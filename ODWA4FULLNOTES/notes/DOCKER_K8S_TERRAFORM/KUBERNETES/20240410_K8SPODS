1. Pod object
Pod is an smallest unit or entity within the kubernetes world, in which one or more containers are kept together and executed. 
	(or)
Pod is an logical grouping of containers which share common attributes or requirements of execution.
	
We might have multiple containerized applications that share common resources/dependencies like
1. network
2. resource files or mounts or volumes
3. lifecycle (start/stop)
	
In such case instead of having these 2 applications running as 2 independent containers, to reduce the effort of managing them , the kubernetes has introduced Pod in which we can place these containers as a single unit and manage it together.

How to write the pod spec file in creating and running a pod on the cluster?
we need to have application binary, that is packaged into docker image and published aspart of the docker container registry. Then we can write pod spec file in creating and running the pod on the cluster	
	
apache2-pod.yml
----------------
---
apiVersion: v1
kind: Pod
metadata:
  name: airtelpod
spec:
  containers:
    - name: apache2
		  image: ubuntu/apache2:latest
			ports:
        - name: http
				  containerPort: 80
					protocol: tcp				
...
						
use kubectl for creating/querying/deleting the pod on the cluster
1. how to create the pod on the cluster?
kubectl -f create apache2-pod.yml

2. how to see the pods on the cluster?
kubectl get pods -n default
	
3. how to see the information about this pod, that we created above?
kubectl describe pod podName

4. How to access the logs that are generated by the pod application while running?
kubectl logs podName

5. How to get more information above the pods that are running on the cluster?
kubectl get pods -o wide

6. how to delete the pod?
kubectl delete podName
(or)
kubectl delete -f airtel2-pod.yml

7. how to expose the pod to the host using port-forwarding?
kubectl port-forward podName hostPort:containerPort

for eg.. kubectl port-forward apache2pod 8080:80
then all the traffic we send to the http://localhost:8080 on the host machine will be send to the pod application that is running on 80 port
--------------------------------------------------------------------------------------------------------------------------------
#1. 	
ReadinessProbe and LivenessProbe
ReadinessProbe and LivenessProbe are the 2 checks that is performed by the kubernetes on the underlying applicationof the pod to report or manage the pod based on real status of the application
	
1. ReadinessProbe
When we pass the kubernetes specfile as an input through kubectl asking the control plane to creating/run the pod, the control plane makes its best effort on determining or identifying an appropriate worknode on the cluster on whom the pod can be scheduled for execution.
	
The kubelet process that is running with in the worker node pull the docker image from the container registry and ask the underlying docker engine to create and run the pod on that worker node, upon creating the pod immediately the control plane reports the pod status as running, even though the underlying application inside the pod has not yet started or running.
	
since the pod status has been reported as running even though the underlying application has not yet started, the control plane will starts routing the requests to the underlying pod application that leads to the failure of those requests. So to avoid this problem of routing the requests to the pod applicatin the Kubernetes has introduced RedinessProbe

The developer of the application has to embed or expose an endpoint aspart of the application to report the ready status of the application (which means is it started and ready for accepting the requests or not). Then define this endpoint information aspart of the podspec file asking the kubernetes to perform the check by accessing this endpoint to verify whether the application is ready or not. Unless the application reports the status as ready kubernetes will not accept or forward the requests to the underlying pod application

2. LivenessProbe
While the pod is running on the cluster, always there is a chance due to lack of resources or failure within the application of the pod the pod may become unresponsive and all the requests that are routed to the pod application results in failure. Since kubernetes will not be aware of such underlying application failures, it still routes the requests to the pod application resulting in failures and wastage of resources in keeping the pod running on the cluster.
	
if the kubernetes can some how know the real running status of the underlying application, it can terminate the pod and recreate another pod on the cluster when the application is not running, this can be done through livenessProbe

The application developer has to build an liveness endpoint that reports the real running status of the application and should configure this endpoint as an livenessProbe within the pod specfile.
	
upon bringing up the pod on the cluster, the kubernetes will periodically performs the liveness check on the pod application based on the configuration we provided to determine whether the underlying application is running or not.	
Unless the readinessProbe has been passed, the kubernetes	will not start performing livenessProbe


We have Roadster java web application, in this application we have #2 endpoints through which we can determine the readiness and liveness of the application as below.
	
1. /actuator/health/readiness
2. /actuator/health/liveness

These endpoints should be configured as readinessProbe and livenessProbe aspart of the kubernetes spec file as below.
	
roadster-pod.yml
----------------
---
apiVersion: v1
kind: Pod
metadata:
  name: roadsterpod
spec:
  containers:
    - name: roadster
		  image: techsriman/roadster:1.0
			ports:
        - name: roadsterhttpport
				  procotol: tcp
					containerPorts: 8080
      readinessProbe:
        httpGet:
          path: /actuator/health/readiness
					port: 8080
				initialDelaySeconds: 5
				timeoutSeconds: 10
				failureThreshold: 3
			livenessProbe:
        httpGet:
          path: /actuator/health/liveness
					port: 8080
				initialDelaySeconds: 5
				timeoutSeconds: 10
				failureThreshold: 3      
...
--------------------------------------------------------------------------------------------------------------------------------
resource declarations
Whenever a pod is running on the Kubernetes cluster, it is going to consume the computing resources like cpu and memory during its execution. The amount of cpu and memory a pod application is going to consume will depends on several factors like
1. nature of the application
2. workload or traffic towards the application
etc

Usually the application would be put for performance testing with performance engineering team, for deriving the bench mark metrics of cpu and memory usage levels of the application. The team puts virtual traffic simulating the real-world requests on the application and derives the min and max resource levels required for running the application

Whenever we schedule a pod for execution, the Kubernetes scheduler takes care of identifying an appropriate workernode on the cluster which has sufficient computing resources available for running the pod application and handovers the pod execution to the kubelet process of the worker node

If we have not specified any resource declaration defining the amount of cpu/memory to be allocated for the pod, the kubernetes allocates the resources based on the amount of the cpu/memory requested by pod itself during its execution, this leads to pod starvation, because when more and more traffic comes towards the pod, it demands more computing resources, that leads to reschedule of pods running on the worker nodes

Instead it is always recommended to define the min/max cpu & memory needed for running the pod application aspart of the kubernetes spec file, so that kubernetes can allocate appropriate resources based on the limits defined. Incase if the traffic increases beyond the resource limits, we need to scale-out the application by running on one more pod and distribute the traffic across these pods using an Service

roadster-pod.yml
-----------------
---
apiVersion: v1
kind: Pod
metadata:
  name: roadsterpod
spec:
  containers:
    - name: roadster
		  image: techsriman/roadster:1.0
			ports:
        - name: roadsterhttp
				  procotol: TCP
					containerPort: 8080
			readinessProbe:
        httpGet
				  path: /roadster/actuator/health/readiness
					port: 8080
				initialDelaySeconds: 5
				timeoutSeconds: 10
				failureThreshold: 3
			livenessProbe:
        httpGet:
          path: /roadster/actuator/health/liveness
					port: 8080
				initialDelaySeconds: 15
				timeoutSeconds: 10
				failureThreshold: 3
			resources:
        requests:
          cpu: "500m"
					memory: "512Mi"
				limits:
          cpu: "1000m"
					memory: "1024Mi"
...

1 core = 1000 millicores = 1000m

Memory 
E = exabyte
P = petabyte
T = terabyte
G = gigabyte
M = megabyte
k = kilobites

You can define mebibytes using Mi as well as Ei, Pi, Ti 
1 mb = 1000 kb
1 MiB = 1048.58 kilobytes
--------------------------------------------------------------------------------------------------------------------------------
What are the different states in which a pod can exists on the kubernetes cluster?
A pod in kubernetes cluster can exists in 5 different states, this is also referred as pod lifecycle

1. pending          = when we requested for creating a pod, the api manager accepts the requests and invokes the scheduler for creating the pod, at this moment the pod state reported as pending. 
2. running          = atleast one of the container inside the pod has been started and readinessProbe for the pod has been passed, the the pod is reported as running
3. succeeded        = all the containers within the pod has exited with an exitcode as "zero", then the pod is reported as succeeded.
4. failed           = when atleast one of the container within the pod as exited with an non-zero exit code, then the pod is reported as failed
5. crashloopbackoff = when a pod is repeatedly failing for execution after a successive restarts, then to avoid further scheduling the pod for execution, kubernetes marks the pod status as "crashloopbackoff" indicating the pod should be scheduled for further execution
--------------------------------------------------------------------------------------------------------------------------------
Working with labels and annotations
Labels:
Labels are the arbitary key/value pairs we can attach to the kubernetes objects. these acts as identifiers using which we can access the objects over the cluster. For an kubernetes object we can assign any number of labels (key/value pairs), but there should be unique and should appear only once

There are 2 ways we attach labels to the kubernetes objects
1. We can declare the labels aspart of the kubernetes spec file or manifest so that the objects would be created with those labels defined
2. We can attach or detach the labels dynamically at runtime using kubectl cli commands

As discused above we can define labels to all the different types of kubernetes objects like
1. pod
2. service
3. job
4. replicaset
5. deploymentset
etc

1. How to declare labels while defining the object information in the spec file itself?
Let us explore how to define labels for an pod object by writing an podspec file

roadster-pod.yml
----------------
---
apiVersion: v1
kind: Pod
metadata:
  name: roadsterpod
  labels:
    appName: roadster
		version: 1.0
		env: prod
spec:
  containers:
    - name: roadster
		  image: techsriman/roadster:1.0
			ports:
        - name: roadsterport
				  containerPort: 8080
					procotol: TCP
...

1. How to see all the labels attached to the pods?
kubectl get pods --show-labels

2. How to query the pods or search based on labels?
kubectl get pods -l key-value

3. how to dynamically attach labels to the object on the cluster?
kubectl label pods podName key=value
--------------------------------------------------------------------------------------------------------------------------------
Annotations
Annotations are used for binding arbitary information which is non-identifier data to any kubernetes objects. These acts as an documentation helps to understand the information about the object like
1. description
2. licensing
3. warranty
4. terms and conditions
etc

We can access this documentation information attached to the objects by using metadata api. We can define the annotations within the spec files, so that the control plane creates the objects adding those annotations defined.
	
roadster-pod.yml
----------------
---
apiVersion: v1
kind: Pod
metadata:
  name: roadsterpod
	labels:
    appName: roadster
		version: 1.0
	annotations:
    license: Apache GNU License2
		description: roadster application is about selling bikes over the online platform
spec:
  containers:
    - name: roadster
		  image: techsriman/roadster:1.0
			ports:
        - name: roadsterport
				  containerPort: 8080
					procotol: TCP
...
						
we can see the annotations of an object using
kubectl describe pod podName
--------------------------------------------------------------------------------------------------------------------------------
ConfigMaps
What is ConfigMaps, what is the purpose of it?
Every software application inorder to implement the business functionality, it has to use external resources/systems like
1. database
2. cache servers
3. messaging systems
etc

How can the software application maintain and use the configuration information pertaining to these resources within their application?
1. hardcode the information about the external resources aspart of the sourcecode of the application itself. This approach has lot of drawbacks
drawbacks:
each time there is change in the external resource, the developers has to modify the programming logic in their application and rebuild, repackage, redeploy and restart the application which is going to incurr huge cost and efforts

2. externalize the configuration within an configuration file
like an XML, JSON, YAML, Properties
The developer within the application writes the code for reading the configurations from the Configuration file and use it within the application
drawbacks:
not suitable for clustered application deployment, as it creates several copies of the configuration per each node on which we deploy and thus maintaining the configuration is difficult

3. centralize and distribute the configuration
publish the configuration information in central config server and pull that configuration within the application and use it
drawbacks:
1. the application will be tightly coupled in using the configuration from that server location, so any change requires modifying the sourcecode, rebuild, redeploy, repackage the application
2. application is exposed to the specific format of the configuration


In order to overcome these problems, rather than application reading the configuration from external source, the application should allow the users to pass the configuration as an input using which it should perform the operation on the external resources.
	
The developer of the application has to design the application to read the configuration values as an input through environment variables, so that while running the application the devops engineer can pass the configuration values as an input by configuring them as environment variables on that machine.
	
How to launch such application that reads the configuration information from environment variables on a kubernetes environment?
The job of scheduling and executing the pod on the nodes of the cluster is taken care by the Control Plane, so that control plane should be able to seed those configuration values as env variables on that node of the cluster before scheduling or executing the pod on the worker node.
	
So we should pass the configuration values as an input to the Control plane, so that it takes care of configuring them as env variables on that worker node before launching the application

How to pass the configuration values as an input to the Control plane?
1. write the configuration values aspart of the pod spec file itself
At first glance it looks like this solution works well, it has lot of problems:
1. everytime there is change in the values of the configurations we need to modify the podspec file which is error prone 
2. if we keep them in the pod spec file, we cannot reuse the same configuration while launching another application, because those are local to the pod
3. while moving or deploying the application across envs, each time we need to modify the pod spec file which is additional maintainance

Instead of writing the configuration values in the pdo specfile, we can place them aspart of the ConfigMap object in the Kubernetes cluster. These configuration values can be accessed across all the node of the cluster. Along with that we can access them as inputs in the pod application in 3 ways
1. environment variables = we can pass these ConfigMap values as environment variables into the pod application by referring them in the pod spec file
2. command-line arguments = we can pass these ConfigMap values as command-line arguments while launching the application
3. through ConfigMap api  = The containerized application developer can write the code in reading the configurations values from ConfigMap object using ConfigMap api

How to work with creating an ConfigMap object on the Kubernetes cluster?
There is an corona application that is taking guidelines as an configuration inputs. So inorder to pass those configurations we need to create ConfigMap object and for that we need to write ConfigMap spec file as below.
	
application requires the below properties
guidelines.oxygenLevels
guidelines.quarantine
guidelines.liters
guidelines.temparatureLevels

The developers has to provide these details of what configurations and their values are required for running the application to the kubernetes developer, so that he can create an ConfigMap specfile defining those configurations and pass them as an input while running the pod

corona-guidelines-configmap.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: guidelinesconfigmap
	labels:
    appName: corona
data:
  oxygenLevels: 80
	quarantine: 20
	liters: 3
	temparatureLevels: 101
		

with these properties we need to create ConfigMap object on the kubernetes cluster
kubectl create -f corona-guidelines-configmap.yml

Now we need to pass these config map properties as an input while running the pod on the cluster as below
corona-pod.yml
---------------
---
apiVersion: v1
kind: Pod
metadata:
  name: coronapod
	labels:
    appName: corona
		version: 1.0
spec:
  containers:
    - name: corona
		  image: techsriman/corona:1.0
			ports:
        - name: http
				  containerPort: 8080
					protocol: TCP
			env:
        - name: guidelines.oxygenLevels
				  valueFrom:
            configMapKeyRef:
              name: guidelinesconfigmap
							key: oxygenLevels
				- name: guidelines.liters
				  valueFrom:
            configMapKeyRef:
              name: guidelinesconfigmap
							key: liters
				- name: guidelines.quarantine
				  valueFrom:
				    configMapKeyRef:
              name: guidelinesconfigmap
							key: quarantine
				- name: guidelines.temparatureLevels
				  valueFrom:
				    configMapKeyRef:
              name: guidelinesconfigmap
							key: temparatureLevels
			volumeMounts:
        - name: healthinspectorvolume
				  mountPath: /config
					readOnly: true
				
							
	volumes:
    - name: healthinspectorvolume 
		  configMap:
        name: healthinspectorconfigmap
				items:
          - key: district-healthinspectors.properties
					  path: "district-healthinspectors.properties"
							

healthinspectors-configmap.yml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: healthinspectorconfigmap
data:
  district-healthinspectors.properties: |
		WestGodavari: Ravi
		EastGodavari: Rajesh
		Krishna: Mahesh
		Nellore: Satish
		Guntur: Kumar
		Kadapa: Sridhar
...
--------------------------------------------------------------------------------------------------------------------------------
Config Secrets
--------------
Kubernetes ConfigSecrets is used for storing and managing the senstive information like passwords, ssh keys, encryption keys etc that are required as an input for the software application. We can store these secrets aspart of the pod spec file or ConfigMap as well, but storing them in pod spec or ConfigMap makes them insecure, because everyone can read the secrets stored aspart of the podspec or configmap and can grab the access to the resources/systems. So it is recommended to store such sentitive information aspart of the ConfigSecrets

Note:
By default when we store the credential information in ConfigSecret it will not be encrypted rather it encodes the data into Base64 encoding standard and will be stored, which means any one can decode and read the text information being stored so it is not secured.	
So kubernetes secrets are stored in HashiCorp Vaults by integrating kubernetes with vendor vaults

When we are storing the sensitive data within the ConfigSecret we can attach type information to help us identify what type of secret we are storing in the ConfigSecret. It is not mandatory to attach type information while storing the ConfigSecret, but it is recommended so that we can easily understand what type of information is stored.
	
By default if we dont specify the "type", the kubernetes treats the type as "opaque"
Kubernetes has provided built-in secret types, we can use these secret types while defining our secrets

1. opaque = arbitary data
2. kubernetes.io/service-account-token=The service account token is a system secret or kubernetes secret
3. kubernetes.io/dockercfg=serialized format of the docker config file
4. kubernetes.io/dockerconfigjson=serialized format of docker config json file
5. kubernetes.io/basic-auth=username/password
6. kubernetes.io/ssh-auth=ssh keys
7. kubernetes.io/tls=ssl keys or public/private encryption keys


We can use the ConfigSecret in 3 ways like ConfigMap
1. we can pass the secrets as environment variables or command-line arguments
2. we can mount the ConfigSecret as file in the pod container
3. The kubelet process itself uses these secrets for connecting to the docker container registry for pulling the images
























			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			

















































		























































































































































































































































































































































	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	








































































	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	