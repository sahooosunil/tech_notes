# AWS Auto Scaling Group Detailed Notes
### What is Auto Scaling?
- Auto Scaling is a cloud computing feature provided by AWS that automatically adjusts the number of EC2 instances in response to changing demand. 
- It ensures that you have the right amount of resources available to handle the load on your application.

###Why is Auto Scaling Required?

- Cost Efficiency: Auto Scaling helps in reducing costs by automatically scaling down resources when they are not needed, ensuring you only pay for what you use.
- Improved Availability: By automatically scaling up resources during high demand, it ensures that your application remains available and performs well.
- Fault Tolerance: Auto Scaling can replace unhealthy instances automatically, ensuring the system's resilience.
- Handling Variable Load: Applications with fluctuating workloads benefit from Auto Scaling by adjusting resources according to the demand.

## 1. Target Group

A **Target Group** is a logical grouping of instances that are part of a load balancing solution in AWS. 
When a load balancer receives a request, it routes the request to one of the registered targets (such as EC2 instances) in the target group.

### Key Features:
- **Load Balancer Association**: Target groups are associated with a load balancer (either an Application Load Balancer or Network Load Balancer).
- **Health Checks**: The load balancer periodically checks the health of the registered targets to ensure they are available to handle requests.
- **Routing Rules**: Based on listener rules, requests can be routed to specific target groups.

### Setting up a Target Group:
1. Go to the AWS Management Console.
2. Navigate to **EC2 > Load Balancers > Target Groups**.
3. Click **Create Target Group**.
4. Choose the **Target Type** (Instances, IP, or Lambda function).
5. Configure **Health Check Settings** (protocol, path, and thresholds).
6. Register targets (EC2 instances).

## 2. Auto Scaling Group

An **Auto Scaling Group (ASG)** is a collection of EC2 instances that are treated as a logical group for automatic scaling and management purposes. 
It ensures that your application always has the right number of instances to handle the load.

### Key Features:
- **Automatic Scaling**: Based on defined policies, the ASG can scale out (add instances) or scale in (remove instances) automatically.
- **Health Monitoring**: ASG monitors the health of instances and replaces unhealthy instances.
- **Elasticity**: Automatically adjusts the number of instances to match demand.

### Setting up an Auto Scaling Group:
1. Go to the AWS Management Console.
2. Navigate to **EC2 > Auto Scaling Groups**.
3. Click **Create Auto Scaling Group**.
4. Choose a **Launch Template** or **Launch Configuration**.
5. Configure the **Group Size** (Desired, Minimum, Maximum instances).
6. Configure **Load Balancing** and select a **Target Group**.
7. Set up **Scaling Policies**.

## 3. Launch Template

A **Launch Template** is a reusable configuration that defines the configuration details for EC2 instances, such as the AMI, instance type, key pair, security groups, and storage volumes.

### Key Features:
- **Versioning**: You can create multiple versions of a launch template, allowing you to maintain and iterate configurations.
- **Parameters**: Define various instance parameters including network interfaces, IAM roles, and monitoring.

### Setting up a Launch Template:
1. Go to the AWS Management Console.
2. Navigate to **EC2 > Launch Templates**.
3. Click **Create Launch Template**.
4. Fill in the required details like **AMI ID**, **Instance Type**, **Key Pair**, **Security Groups**, etc.
5. Save the template.

## 4. Relationship Between Load Balancer, Node Group, Target Group

### Load Balancer
- Distributes incoming application traffic across multiple targets (EC2 instances) in one or more Availability Zones.

### Target Group
- Contains the targets (EC2 instances) that the load balancer directs traffic to.

### Node Group (in context of Kubernetes or EKS)
- A group of EC2 instances that serve as worker nodes for running containerized applications.

### Relationship:
- **Load Balancer** routes traffic based on listener rules to a **Target Group**.
- The **Target Group** contains instances from an **Auto Scaling Group**.
- The **Auto Scaling Group** manages instances that could be part of a **Node Group** in EKS, handling the scaling and health of instances.

## 5. Health Check (In Detail)

### Health Check Process:
- Performed by both the Load Balancer and Auto Scaling Group.
- **Load Balancer Health Check**: Regularly pings the instances to check their availability and responsiveness. If an instance fails, it is marked as unhealthy, and traffic is rerouted.
  - **Configuration**: Set protocol (HTTP/HTTPS/TCP), path (e.g., `/healthcheck`), interval, timeout, and success thresholds.
- **Auto Scaling Group Health Check**: ASG can use ELB health checks or EC2 status checks to monitor instance health.
  - If an instance fails, ASG automatically terminates it and launches a replacement.

### Setting Health Checks:
1. Navigate to **EC2 > Load Balancers > Target Groups**.
2. Select the target group and configure the health check settings.
3. For ASG, go to **EC2 > Auto Scaling Groups**, select the ASG, and configure health checks under the **Details** tab.

## 6. Desired Size, Max, Min Size

### Definitions:
- **Desired Size**: The ideal number of instances that the ASG aims to maintain.
- **Maximum Size**: The upper limit of instances that the ASG can scale out to.
- **Minimum Size**: The lower limit of instances that the ASG will maintain, even if there is no demand.

### Example:
- **Desired Size**: 3
- **Min Size**: 2
- **Max Size**: 5

The ASG will maintain 3 instances under normal conditions, but can scale down to 2 or up to 5 based on demand.

## 7. Parameters for Auto Scaling (In Detail)

### Scaling Triggers:
- **CPU Utilization**: Scale out when average CPU usage across instances exceeds a threshold (e.g., 70%).
- **Memory Utilization**: Scale based on available memory.
- **Request Count per Target**: Scale based on the number of incoming requests.
- **Custom Metrics**: Use CloudWatch custom metrics for specific application needs.

### Scaling Policies:
- **Simple Scaling**: Adds/removes instances based on a single scaling action.
- **Step Scaling**: Adds/removes instances in steps based on increasing levels of demand.
- **Target Tracking**: Maintains a target metric (e.g., 50% CPU usage).

### Scaling Down:
- Occurs when the load decreases below defined thresholds. 
ASG terminates instances based on the policies and health checks.

## 8. Installing Software on Scaling

### Automating Software Installation:
1. **User Data Scripts**: Provide a script during instance launch to install and configure software.
2. **AMI Pre-baking**: Create a custom AMI with pre-installed software.
3. **Configuration Management Tools**:
   - **AWS Systems Manager (SSM)**: Automate software installation and configuration.
   - **Chef/Puppet/Ansible**: Automate instance configuration.

### Handling Errors:
- **User Data Errors**: If a script fails, the instance may be marked as unhealthy.
- **Automated Recovery**: ASG can replace the failed instance automatically.

### Steps for User Data Script:
1. Include the script in the Launch Template under **Advanced Details**.
2. Ensure the script installs required packages and handles errors gracefully.
---------------------------------------------------------------------------------
### Steps to Set Up AWS Auto Scaling with Load Balancer and Target Group

#### 1. **Create a Load Balancer**
   - **Step 1:** Go to the AWS Management Console.
   - **Step 2:** Navigate to **EC2 Dashboard** > **Load Balancers**.
   - **Step 3:** Click on **Create Load Balancer**.
   - **Step 4:** Choose the type of load balancer:
     - **Application Load Balancer (ALB)**: Best for HTTP/HTTPS traffic.
     - **Network Load Balancer (NLB)**: Best for TCP, UDP, or TLS traffic.
     - **Classic Load Balancer (CLB)**: Older generation, supports basic routing.
   - **Step 5:** Configure load balancer settings:
     - **Name**: Enter a name for the load balancer.
     - **Scheme**: Choose internet-facing or internal.
     - **IP Address Type**: Choose IPv4 or dualstack.
     - **Listeners**: Configure listener ports and protocols.
   - **Step 6:** Configure security groups to allow traffic.
   - **Step 7:** Configure routing settings by attaching a target group.
   - **Step 8:** Register targets (optional; can be done later).
   - **Step 9:** Review and create the load balancer.

#### 2. **Create a Target Group**
   - **Step 1:** Navigate to **EC2 Dashboard** > **Target Groups**.
   - **Step 2:** Click on **Create target group**.
   - **Step 3:** Choose the target type (e.g., **Instances**, **IP addresses**, **Lambda functions**).
   - **Step 4:** Configure the target group settings:
     - **Name**: Provide a name for the target group.
     - **Protocol**: Choose the protocol (HTTP, HTTPS, TCP).
     - **Port**: Specify the port the target group will use.
     - **VPC**: Select the appropriate VPC.
     - **Health checks**: Configure health check protocol, path, and intervals.
   - **Step 5:** Review and create the target group.

#### 3. **Attach Target Group to Load Balancer**
   - **Step 1:** After creating the target group, go back to your **Load Balancer**.
   - **Step 2:** Select the load balancer you created.
   - **Step 3:** Under **Listeners**, click on **Add listener** or edit the existing one.
   - **Step 4:** Configure the listener to forward traffic to the target group:
     - Choose the protocol and port for incoming traffic.
     - Select the target group created earlier for routing.
   - **Step 5:** Save the changes.

#### 4. **Create an Auto Scaling Group**
   - **Step 1:** Navigate to **EC2 Dashboard** > **Auto Scaling Groups**.
   - **Step 2:** Click on **Create Auto Scaling group**.
   - **Step 3:** Configure the **Auto Scaling group**:
     - **Name**: Enter a name.
     - **Launch Template**: Choose an existing template or create a new one.
   - **Step 4:** Configure **Network and Subnets**:
     - Select the appropriate VPC and subnets.
   - **Step 5:** Configure **Load balancing**:
     - Attach the Auto Scaling group to the previously created target group.
   - **Step 6:** Set desired, minimum, and maximum instance sizes.
   - **Step 7:** Configure scaling policies (based on metrics like CPU utilization).
   - **Step 8:** Add notifications and tags if required.
   - **Step 9:** Review and create the Auto Scaling group.

#### 5. **Attach Auto Scaling Group to Target Group**
   - During the setup of the Auto Scaling group, you would have already attached it to the target group in the load balancing step.

---

### Traffic Flow from User to Application Inside EC2

1. **User Browser:** 
   - A user opens their browser and enters a URL.
   
2. **DNS Resolution:**
   - The domain name is resolved to the IP address of the Load Balancer using DNS services (e.g., Route 53).

3. **Load Balancer:**
   - The request hits the Load Balancer, which acts as the entry point to distribute incoming traffic.
   - The Load Balancer listens on specific ports and protocols and routes traffic to the appropriate target group.

4. **Target Group:**
   - The Load Balancer forwards the traffic to the associated Target Group based on routing rules.
   - The Target Group maintains a list of healthy instances (EC2 instances) based on health checks.

5. **Auto Scaling Group:**
   - The Target Group is linked to an Auto Scaling Group, which manages the EC2 instances.
   - Auto Scaling ensures that the correct number of instances is running, based on the desired, minimum, and maximum size configurations.

6. **EC2 Instances:**
   - The traffic is routed to one of the EC2 instances in the Auto Scaling Group.
   - The instance processes the request and serves the application’s content or performs backend operations.

7. **Application Inside EC2:**
   - The application inside the EC2 instance handles the request (e.g., serving a web page, processing data).
   - The response is sent back through the Load Balancer to the user's browser.

By following these steps and understanding the traffic flow, you ensure a scalable, reliable, and resilient application deployment on AWS.
--------------------------------------------------------------------------------

### Differences Between AWS Auto Scaling and Kubernetes

#### AWS Auto Scaling
AWS Auto Scaling is a service that helps automatically adjust the number of EC2 instances in a group based on demand.

**Key Features:**
1. **Instance-Based Scaling:** Primarily focused on scaling EC2 instances.
2. **Integration:** Tightly integrated with other AWS services like Elastic Load Balancing (ELB), CloudWatch, and AWS Elastic Beanstalk.
3. **Scaling Policies:** Supports dynamic scaling (based on metrics) and scheduled scaling.
4. **Simple Setup:** Easier to set up and manage for applications running directly on EC2.
5. **Lifecycle Management:** Allows scaling based on various lifecycle hooks, such as instance launch or termination.

**Advantages:**
- **Seamless Integration:** Works seamlessly within the AWS ecosystem.
- **Ease of Use:** Simpler for applications that don’t require container orchestration.
- **Cost-Effective:** Automatically adjusts the number of instances to optimize costs.

**Disadvantages:**
- **Limited Container Support:** Not natively designed for containerized applications.
- **Static Environment:** Less flexible for complex, containerized workloads compared to Kubernetes.

---

#### Kubernetes (K8s)
Kubernetes is an open-source container orchestration platform that automates deployment, scaling, and management of containerized applications.

**Key Features:**
1. **Pod-Based Scaling:** Focuses on scaling containers (pods) rather than instances.
2. **Container Orchestration:** Provides robust management of containerized applications across a cluster.
3. **Multi-Cloud/Hybrid Support:** Can run on any cloud or on-premises, not tied to a single provider.
4. **Horizontal Pod Autoscaler (HPA):** Scales pods based on metrics like CPU, memory, or custom metrics.
5. **Rolling Updates:** Supports seamless updates and rollbacks for applications.

**Advantages:**
- **Flexibility:** Supports a wide range of applications, especially containerized workloads.
- **Portability:** Applications can be deployed across multiple environments (on-premises, cloud).
- **Extensibility:** Rich ecosystem with many add-ons for monitoring, logging, and networking.

**Disadvantages:**
- **Complexity:** More complex to set up and manage than AWS Auto Scaling.
- **Learning Curve:** Requires a deeper understanding of containerization and orchestration.
- **Resource Overhead:** May require more resources and maintenance for managing the control plane.

---

### When to Choose AWS Auto Scaling vs. Kubernetes

#### **Use AWS Auto Scaling When:**
1. **Simple EC2 Workloads:** Your application runs directly on EC2 instances without containers.
2. **AWS-Centric Applications:** You are heavily invested in the AWS ecosystem.
3. **Ease of Management:** You prefer a simpler setup with less management overhead.
4. **Cost Optimization:** You want to focus on instance-level scaling to optimize costs.

#### **Use Kubernetes When:**
1. **Containerized Applications:** Your applications are containerized and need orchestration.
2. **Complex Workloads:** You require features like rolling updates, service discovery, and load balancing for microservices.
3. **Portability:** You need a solution that can run across multiple environments (cloud, on-premises).
4. **Scalability and Flexibility:** You want fine-grained control over application scaling and deployment strategies.

### Summary
- **AWS Auto Scaling** is best for simpler, instance-based applications within AWS.
- **Kubernetes** is ideal for containerized applications requiring orchestration and portability.

**Choosing between them depends on your application architecture, deployment environment, and operational needs.** If your application is containerized or you plan to adopt microservices, Kubernetes is a better choice. For simpler, AWS-centric applications, AWS Auto Scaling may be sufficient.